{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "MIN_SIMILARITY_WITH_GT_REGION = 0.5\n",
    "MIN_SIMILARITY_WITH_NEIGHBOR_BBOX = 0.5\n",
    "NeedFastSeSe = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCameraParams ( isColor: bool ) :\n",
    "    # TODO : consider distortion\n",
    "\n",
    "    # RGB Intrinsic Parameters\n",
    "    fx_rgb = 5.1885790117450188e+02\n",
    "    fy_rgb = 5.1946961112127485e+02\n",
    "    cx_rgb = 3.2558244941119034e+02\n",
    "    cy_rgb = 2.5373616633400465e+02\n",
    "    # # RGB Distortion Parameters\n",
    "    # k1_rgb =  2.0796615318809061e-01\n",
    "    # k2_rgb = -5.8613825163911781e-01\n",
    "    # k3_rgb = 4.9856986684705107e-01\n",
    "    # p1_rgb = 7.2231363135888329e-04\n",
    "    # p2_rgb = 1.0479627195765181e-03\n",
    "\n",
    "    # Depth Intrinsic Parameters\n",
    "    fx_d = 5.8262448167737955e+02\n",
    "    fy_d = 5.8269103270988637e+02\n",
    "    cx_d = 3.1304475870804731e+02\n",
    "    cy_d = 2.3844389626620386e+02\n",
    "    # # RGB Distortion Parameters\n",
    "    # k1_d = -9.9897236553084481e-02\n",
    "    # k2_d = 3.9065324602765344e-01\n",
    "    # k3_d = -5.1031725053400578e-01\n",
    "    # p1_d = 1.9290592870229277e-03\n",
    "    # p2_d = -1.9422022475975055e-03\n",
    "\n",
    "    if isColor :\n",
    "        return cx_rgb, cy_rgb, fx_rgb, fy_rgb\n",
    "    return cx_d, cy_d, fx_d, fy_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImages ( img_name: str, root_dir: str = \"../nyudv2\", print_info: bool = False ) :\n",
    "    start = time.time()\n",
    "\n",
    "    # image = cv2.imread(f\"{root_dir}/rgb_{img_name}.png\")\n",
    "    # image_depth = np.mean(cv2.imread(f\"{root_dir}/depth_{img_name}.png\"), axis=2)\n",
    "    # image_labelmaps = cv2.imread(f\"{root_dir}/label_maps_{img_name}.png\")\n",
    "    image = np.load(f\"{root_dir}/rgb/{img_name}.npy\")\n",
    "    image_depth = np.load(f\"{root_dir}/depth/{img_name}.npy\")\n",
    "    image_labelmaps = np.load(f\"{root_dir}/label/{img_name}.npy\")\n",
    "    image_instmaps = np.load(f\"{root_dir}/instance/{img_name}.npy\")\n",
    "\n",
    "    image_hha = cv2.imread(f\"{root_dir}/hha/{img_name}.png\")\n",
    "\n",
    "    image_xyz = np.zeros((image_depth.shape[0], image_depth.shape[1], 3))\n",
    "    height, width = image_depth.shape\n",
    "    CX_DEPTH, CY_DEPTH, FX_DEPTH, FY_DEPTH = getCameraParams(isColor=False)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            z = image_depth[i,j]\n",
    "            x = (j - CX_DEPTH) * z / FX_DEPTH\n",
    "            y = (i - CY_DEPTH) * z / FY_DEPTH\n",
    "            image_xyz[i,j] = [x, y, z]\n",
    "\n",
    "    image_labinsts = np.concatenate((image_labelmaps[:, :, np.newaxis], image_instmaps[:, :, np.newaxis]), axis=-1)\n",
    "    fg_linsts = np.array(list({ (l,i) for l, i in image_labinsts.reshape(-1, 2) if l != 0 and i != 0 })) # 0 is background (boundaries, etc)\n",
    "\n",
    "    allmasks, am_label, am_instance, am_area = list(), list(), list(), list()\n",
    "    for label, inst in fg_linsts :\n",
    "        mask = (image_labinsts[:, :, 0] == label) & (image_labinsts[:, :, 1] == inst)\n",
    "        allmasks.append(mask)\n",
    "        am_label.append(label)\n",
    "        am_instance.append(inst)\n",
    "        am_area.append(np.sum(mask))\n",
    "    allmasks = np.array(allmasks)\n",
    "    am_label = np.array(am_label)\n",
    "    am_instance = np.array(am_instance)\n",
    "    am_area = np.array(am_area)\n",
    "\n",
    "    if print_info :\n",
    "        unilm = np.unique(image_labelmaps)\n",
    "        print(f\"[INFO] unique label classes: {unilm}\")\n",
    "        print(f\"[INFO] number of unique label classes: {len(unilm)}\")\n",
    "        print(f\"[INFO] all images loaded in {time.time() - start:.4f}s\")\n",
    "\n",
    "    # ensure all of these are np arrays\n",
    "    return image, image_depth, image_hha, image_xyz, image_labinsts, allmasks, am_label, am_instance, am_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images ( image, image_depth, image_hha ) :\n",
    "    _, subplts = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    subplts[0].imshow(image)\n",
    "    subplts[0].axis('off')\n",
    "    subplts[1].imshow(image_depth)\n",
    "    subplts[1].axis('off')\n",
    "    subplts[2].imshow(image_hha)\n",
    "    subplts[2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hha_components ( image_hha ) :\n",
    "    _, subplts = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    subplts[0].imshow(image_hha[:, :, 0])\n",
    "    subplts[0].axis('off')\n",
    "    subplts[1].imshow(image_hha[:, :, 1])\n",
    "    subplts[1].axis('off')\n",
    "    subplts[2].imshow(image_hha[:, :, 2])\n",
    "    subplts[2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_angle_directions ( image_hha ) :\n",
    "    down = image_hha[:, :, 0] < 255/3\n",
    "    horiz = ( 255/3 <= image_hha[:, :, 0] ) & ( image_hha[:, :, 0] < 2*255/3 )\n",
    "    up = 2*255/3 <= image_hha[:, :, 0]\n",
    "\n",
    "    _, subplts = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    subplts[0].imshow(down)\n",
    "    subplts[0].axis('off')\n",
    "    subplts[1].imshow(horiz)\n",
    "    subplts[1].axis('off')\n",
    "    subplts[2].imshow(up)\n",
    "    subplts[2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_masks ( allmasks, am_label, am_instance ) :\n",
    "    masks_per_row = 5\n",
    "    _, subplts = plt.subplots(int(np.ceil(len(allmasks)/masks_per_row)), masks_per_row, figsize=(20, 10))\n",
    "    for subplt in subplts.flatten() :\n",
    "        subplt.axis('off')\n",
    "    for idx, (l, i, imask) in enumerate(zip(am_label, am_instance, allmasks)) :\n",
    "        subplts[idx//masks_per_row][idx%masks_per_row].imshow(imask)\n",
    "        subplts[idx//masks_per_row][idx%masks_per_row].axis('off')\n",
    "        subplts[idx//masks_per_row][idx%masks_per_row].set_title(f\"{l}, {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performSeSe ( image, image_hha, print_info=False ) :\n",
    "\tstart = time.time()\n",
    "\tss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\tss.setBaseImage(image)\n",
    "\tss.addImage(image_hha) # TODO : test reverse order\n",
    "\tif NeedFastSeSe :\n",
    "\t\tif print_info :\n",
    "\t\t\tprint(\"[INFO] using *fast* selective search\")\n",
    "\t\tss.switchToSelectiveSearchFast()\n",
    "\telse:\n",
    "\t\tif print_info :\n",
    "\t\t\tprint(\"[INFO] using *quality* selective search\")\n",
    "\t\tss.switchToSelectiveSearchQuality()\n",
    "\tbboxes = ss.process()\n",
    "\tif print_info :\n",
    "\t\tprint(f\"[INFO] total number of region proposals: {len(bboxes)}\")\n",
    "\t\tprint(f\"[INFO] basic region proposal took {time.time()-start:.4f} seconds\")\n",
    "\treturn bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSeSeBBoxes ( image, rects ) :\n",
    "\tbocses_per = 30\n",
    "\tfor i in range(0, len(rects), bocses_per):\n",
    "\t\toutput = image.copy()\n",
    "\t\tfor (x, y, w, h) in rects[i:i + bocses_per]:\n",
    "\t\t\tcolor = [random.randint(0, 255) for _ in range(0, 3)]\n",
    "\t\t\tcv2.rectangle(output, (x, y), (x + w, y + h), color, 2)\n",
    "\t\tcv2.imshow(\"Output\", output)\n",
    "\t\tkey = cv2.waitKey(0) & 0xFF\n",
    "\t\tif key == ord(\"q\"):\n",
    "\t\t\tbreak\n",
    "\tcv2.destroyWindow(\"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_region_label ( bbox_labinsts, bbox_masks, am_label, am_instance, am_area ) :\n",
    "    best_class, best_score = 0, MIN_SIMILARITY_WITH_GT_REGION\n",
    "    labels_in_question = np.unique(bbox_labinsts[:, :, 0])\n",
    "    insts_in_question = np.unique(bbox_labinsts[:, :, 1])\n",
    "    w, h = bbox_masks.shape[1:]\n",
    "\n",
    "    for label, inst, area, mask_region in zip(am_label, am_instance, am_area, bbox_masks) :\n",
    "        if label not in labels_in_question or inst not in insts_in_question :\n",
    "            continue\n",
    "        intersection_area = np.sum(mask_region) # TODO : can be made faster by saving the tight bounding box of the mask and only checking that area\n",
    "        # TODO : check if it could be better to calculate the intersection between bounding box and tight bounding box of mask\n",
    "        sim = intersection_area / ( area + w*h - intersection_area ) # using jaccard similarity as per the paper\n",
    "        if sim > best_score :\n",
    "            best_score, best_class = sim, label\n",
    "    return best_class, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_jaccardsimilarity ( bb1, bb2 ) :\n",
    "    x1,y1,w1,h1 = bb1\n",
    "    x2,y2,w2,h2 = bb2\n",
    "    x_intersection = max(x1, x2)\n",
    "    y_intersection = max(y1, y2)\n",
    "    w_intersection = min(x1+w1, x2+w2) - x_intersection\n",
    "    h_intersection = min(y1+h1, y2+h2) - y_intersection\n",
    "\n",
    "    if w_intersection <= 0 or h_intersection <= 0 :\n",
    "        return 0.0\n",
    "    intersection_area = w_intersection * h_intersection\n",
    "    iou = ( intersection_area ) / ( w1*h1 + w2*h2 - intersection_area )\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supress_non_maximal_boxes ( rects, image_labinsts, allmasks, am_label, am_instance, am_area, print_info=False ) :\n",
    "    start = time.time()\n",
    "    data_unsupressed = list()\n",
    "    for (x, y, w, h) in rects :\n",
    "        gt_label, gt_score = ground_truth_region_label(image_labinsts[y:y+h, x:x+w], allmasks[:, y:y+h, x:x+w], am_label, am_instance, am_area)\n",
    "        data_unsupressed.append((x, y, w, h, gt_label, gt_score))\n",
    "    data_unsupressed = np.asanyarray(data_unsupressed)\n",
    "    sorting_order = data_unsupressed[:, -1].argsort()[::-1]\n",
    "    data_unsupressed = data_unsupressed[sorting_order]\n",
    "    # NOTE : now the data_unsupressed is sorted by gt_score (descending order)\n",
    "\n",
    "    if print_info :\n",
    "        print(f\"[INFO] label and score calculation took {time.time()-start:.4f}s\")\n",
    "        start = time.time()\n",
    "\n",
    "    # supress non maximal boxes\n",
    "    regions_supressed, labels_supressed, scores_supressed = list(), list(), list()\n",
    "    for data in data_unsupressed :\n",
    "        bb = data[:4]\n",
    "        for bb_ in regions_supressed :\n",
    "            if bb_jaccardsimilarity(bb, bb_) > MIN_SIMILARITY_WITH_NEIGHBOR_BBOX :\n",
    "                break\n",
    "        else :\n",
    "            # NOTE : this is not a typo, it is a python feature\n",
    "            # NOTE : code reaches here only if the above for loop is not exited by break\n",
    "            regions_supressed.append(bb)\n",
    "            labels_supressed.append(data[4])\n",
    "            scores_supressed.append(data[5])\n",
    "    regions_supressed = np.asanyarray(regions_supressed).astype(int)\n",
    "    labels_supressed = np.asanyarray(labels_supressed).astype(int)\n",
    "    scores_supressed = np.asanyarray(scores_supressed)\n",
    "\n",
    "    if print_info :\n",
    "        print(f\"[INFO] number of boxes after supression: {len(labels_supressed)}\")\n",
    "        print(f\"[INFO] non-maximum supression took {time.time()-start:.4f}s\")\n",
    "    return regions_supressed, labels_supressed, scores_supressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features ( image, image_depth, image_hha, image_xyz, regions_supressed, labels_supressed, scores_supressed, print_info: bool = False ) :\n",
    "    start = time.time()\n",
    "    X_supressed, Y_supressed = list(), list()\n",
    "    for (x, y, w, h), gt_label, gt_score in zip(regions_supressed, labels_supressed, scores_supressed) :\n",
    "        proposed_box_rgb = image[y:y+h, x:x+w]\n",
    "        proposed_box_depth = image_depth[y:y+h, x:x+w]\n",
    "        proposed_box_angle = image_hha[y:y+h, x:x+w][:, :, 0]\n",
    "        proposed_box_height = image_hha[y:y+h, x:x+w][:, :, 1]\n",
    "        proposed_box_disparity = image_hha[y:y+h, x:x+w][:, :, 2]\n",
    "        proposed_box_xyz = image_xyz[y:y+h, x:x+w].reshape(-1, 3)\n",
    "\n",
    "        depth_mean_sd = np.mean(proposed_box_depth), np.std(proposed_box_depth)\n",
    "        height_mean_sd = np.mean(proposed_box_height), np.std(proposed_box_height)\n",
    "        angle_mean_sd = np.mean(proposed_box_angle), np.std(proposed_box_angle)\n",
    "        disparity_mean_sd = np.mean(proposed_box_disparity), np.std(proposed_box_disparity)\n",
    "        x_mean_sd = np.mean(proposed_box_xyz[:, 0]), np.std(proposed_box_xyz[:, 0])\n",
    "        y_mean_sd = np.mean(proposed_box_xyz[:, 1]), np.std(proposed_box_xyz[:, 1])\n",
    "        z_mean_sd = np.mean(proposed_box_xyz[:, 2]), np.std(proposed_box_xyz[:, 2])\n",
    "        extent_x = np.max(proposed_box_xyz[:, 0]) - np.min(proposed_box_xyz[:, 0])\n",
    "        extent_y = np.max(proposed_box_xyz[:, 1]) - np.min(proposed_box_xyz[:, 1])\n",
    "        extent_z = np.max(proposed_box_xyz[:, 2]) - np.min(proposed_box_xyz[:, 2])\n",
    "        min_height = np.min(proposed_box_height)\n",
    "        max_height = np.max(proposed_box_height)\n",
    "        frac_facing_down = np.sum(proposed_box_angle < 255/3) / (w*h)\n",
    "        frac_facing_horiz = np.sum(( 255/3 <= proposed_box_angle ) & ( proposed_box_angle < 2*255/3 )) / (w*h)\n",
    "        frac_facing_up = np.sum(2*255/3 <= proposed_box_angle) / (w*h)\n",
    "\n",
    "        area = w*h\n",
    "        perimeter = 2*(w+h)\n",
    "        location = x / image.shape[1], y / image.shape[0]\n",
    "        aspect_ratio = w / h\n",
    "        # perimeter (and sum of contour strength) divided by the squared root of the area\n",
    "        # area of the region divided by that of the bounding box.\n",
    "        # Sum of contour strength at the boundaries\n",
    "        # mean contour strength at the boundaries\n",
    "        # minimum and maximum UCM threshold of appearance and disappearance of the regions forming the candidate.\n",
    "\n",
    "        r_mean_sd = np.mean(proposed_box_rgb[:, :, 0]), np.std(proposed_box_rgb[:, :, 0])\n",
    "        g_mean_sd = np.mean(proposed_box_rgb[:, :, 1]), np.std(proposed_box_rgb[:, :, 1])\n",
    "        b_mean_sd = np.mean(proposed_box_rgb[:, :, 2]), np.std(proposed_box_rgb[:, :, 2])\n",
    "        d_mean_sd = np.mean(proposed_box_depth), np.std(proposed_box_depth)\n",
    "\n",
    "        features = [ gt_score,x,y,w,h, *depth_mean_sd, *height_mean_sd, *angle_mean_sd, *disparity_mean_sd, *x_mean_sd, *y_mean_sd, *z_mean_sd, extent_x, extent_y, extent_z, min_height, max_height, frac_facing_down, frac_facing_horiz, frac_facing_up, area, perimeter, *location, aspect_ratio, *r_mean_sd, *g_mean_sd, *b_mean_sd, *d_mean_sd ]\n",
    "        # NOTE : remove gt_score,x,y,w,h from features before training\n",
    "        X_supressed.append(features)\n",
    "        Y_supressed.append(gt_label)\n",
    "    X_supressed = np.asanyarray(X_supressed)\n",
    "    Y_supressed = np.asanyarray(Y_supressed)\n",
    "    \n",
    "    if print_info :\n",
    "        print(\"[INFO] classes and their counts:\")\n",
    "        print(np.asanyarray(np.unique(labels_supressed, return_counts=True)).T)\n",
    "        print(\"[INFO] number of classes excluding background : \", len(np.unique(labels_supressed[labels_supressed!=0])))\n",
    "        print(f\"[INFO] feature extraction took {time.time()-start:.4f} seconds\")\n",
    "    return X_supressed, Y_supressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selected_regions ( image, regions_supressed, Y_supressed ) :\n",
    "    pics_per_row = 4\n",
    "    _, subplts = plt.subplots(int(np.ceil(np.sum(Y_supressed!=0)/pics_per_row)), pics_per_row, figsize=(20, 20))\n",
    "    for subplt in subplts.flatten() :\n",
    "        subplt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for idx, ids in enumerate(np.argwhere(Y_supressed != 0).flatten()) :\n",
    "        x, y, w, h = regions_supressed[ids]\n",
    "        output = np.zeros_like(image)\n",
    "        output[y:y+h, x:x+w] = image[y:y+h, x:x+w]\n",
    "        # print(f\"pred class = {Y_supressed[ids]}\")\n",
    "        subplts[idx//pics_per_row][idx%pics_per_row].imshow(output)\n",
    "        subplts[idx//pics_per_row][idx%pics_per_row].set_title(Y_supressed[ids])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_filename ( imgnumber, print_plots=False, print_info=False ) :\n",
    "    tic = time.time()\n",
    "    image, image_depth, image_hha, image_xyz, image_labinsts, allmasks, am_label, am_instance, am_area = getImages(imgnumber, print_info=print_info)\n",
    "    if print_plots :\n",
    "        plot_masks(allmasks, am_label, am_instance)\n",
    "    allbboxes = performSeSe(image, image_hha, print_info=print_info)\n",
    "    bboxes, labels, scores = supress_non_maximal_boxes(allbboxes, image_labinsts, allmasks, am_label, am_instance, am_area, print_info=print_info)\n",
    "    X, Y = extract_features(image, image_depth, image_hha, image_xyz, bboxes, labels, scores, print_info=print_info)\n",
    "    if print_plots :\n",
    "        plot_selected_regions(image, bboxes, Y)\n",
    "    if print_info :\n",
    "        print(f\"[INFO] X-> {X.shape} \\t Y-> {Y.shape}\")\n",
    "        print(f\"[INFO] total time taken {time.time()-tic:.4f} seconds\")\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] unique label classes: [ 0  2  3  5 15 21 34 35 36 37]\n",
      "[INFO] number of unique label classes: 10\n",
      "[INFO] all images loaded in 2.0767s\n",
      "[INFO] using *quality* selective search\n",
      "[INFO] total number of region proposals: 6594\n",
      "[INFO] basic region proposal took 10.3028 seconds\n",
      "[INFO] label and score calculation took 6.6721s\n",
      "[INFO] number of boxes after supression: 925\n",
      "[INFO] non-maximum supression took 2.4808s\n",
      "[INFO] classes and their counts:\n",
      "[[  0 906]\n",
      " [  2   4]\n",
      " [  5   1]\n",
      " [ 15   5]\n",
      " [ 21   3]\n",
      " [ 34   1]\n",
      " [ 35   1]\n",
      " [ 36   1]\n",
      " [ 37   3]]\n",
      "[INFO] number of classes excluding background :  8\n",
      "[INFO] feature extraction took 0.4521 seconds\n",
      "[INFO] X-> (925, 40) \t Y-> (925,)\n",
      "[INFO] total time taken 21.9854 seconds\n"
     ]
    }
   ],
   "source": [
    "X__, Y__ = get_features_from_filename(\"3\", print_plots=False, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] unique label classes: [  0  11  21  42  55  59  64  66  74  78  81 119 141 157 158]\n",
      "[INFO] number of unique label classes: 15\n",
      "[INFO] all images loaded in 1.9625s\n",
      "[INFO] using *quality* selective search\n",
      "[INFO] total number of region proposals: 7492\n",
      "[INFO] basic region proposal took 8.3346 seconds\n",
      "[INFO] label and score calculation took 6.1502s\n",
      "[INFO] number of boxes after supression: 1042\n",
      "[INFO] non-maximum supression took 3.0868s\n",
      "[INFO] classes and their counts:\n",
      "[[   0 1016]\n",
      " [  11    1]\n",
      " [  21    3]\n",
      " [  42    1]\n",
      " [  55    2]\n",
      " [  59    2]\n",
      " [  64    4]\n",
      " [  66    2]\n",
      " [  74    1]\n",
      " [  78    1]\n",
      " [  81    3]\n",
      " [ 119    1]\n",
      " [ 141    2]\n",
      " [ 157    1]\n",
      " [ 158    2]]\n",
      "[INFO] number of classes excluding background :  14\n",
      "[INFO] feature extraction took 0.5105 seconds\n",
      "[INFO] X-> (1042, 40) \t Y-> (1042,)\n",
      "[INFO] total time taken 20.0448 seconds\n"
     ]
    }
   ],
   "source": [
    "X__, Y__ = get_features_from_filename(\"69\", print_plots=False, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] unique label classes: [  0   2   4  21  64  74  85 119 144 157 158]\n",
      "[INFO] number of unique label classes: 11\n",
      "[INFO] all images loaded in 1.9989s\n",
      "[INFO] using *quality* selective search\n",
      "[INFO] total number of region proposals: 3184\n",
      "[INFO] basic region proposal took 8.9336 seconds\n",
      "[INFO] label and score calculation took 2.2131s\n",
      "[INFO] number of boxes after supression: 529\n",
      "[INFO] non-maximum supression took 0.7549s\n",
      "[INFO] classes and their counts:\n",
      "[[  0 508]\n",
      " [  2   1]\n",
      " [  4   1]\n",
      " [ 21   2]\n",
      " [ 64   6]\n",
      " [ 74   2]\n",
      " [ 85   1]\n",
      " [119   3]\n",
      " [144   2]\n",
      " [157   2]\n",
      " [158   1]]\n",
      "[INFO] number of classes excluding background :  10\n",
      "[INFO] feature extraction took 0.2870 seconds\n",
      "[INFO] X-> (529, 40) \t Y-> (529,)\n",
      "[INFO] total time taken 14.1878 seconds\n"
     ]
    }
   ],
   "source": [
    "X__, Y__ = get_features_from_filename(\"72\", print_plots=False, print_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
